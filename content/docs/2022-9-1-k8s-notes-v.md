+++
title="K8s 笔记 (V)"
description="服务，负载均衡和网络"
date=2022-09-01

[taxonomies]
categories = ["Doc"]
tags = ["k8s"]

[extra]
toc = true
+++

## 简介

### K8s 网络模型

每个在集群里的 `Pod` 都有其唯一的 IP 地址。这就意味着用户不需要显式的创建 `Pods` 直接的连接，同时几乎不用处理容器端口与主机端口的映射。这就创建了一个干净的，向后兼容的模型，从端口分配，命名，服务发现，负载均衡，应用配置和迁移的角度来看，`Pods` 可以被视为 VMs 或者物理主机。

对任何网络设施，k8s 强制要求下列基础需求（使得排除掉有意隔离网络的策略）：

- Pod 能够与其他节点上的 Pod 通信，且不需要网络地址转译（NAT）
- 节点上的代理（比如：系统守护进程，kubelet）可以和节点上的所有 Pod 通信

注意：这些支持 `Pods` 运行在主机网络（例如 Linux）的平台，当 pods 连接到一个节点的主机网络，它们仍然可以不使用 NAT 与其他所有节点的 pods 通信。

这个模型不仅不复杂，而且还和 k8s 的实现从虚拟机向容器平滑迁移的初衷相符，如果任务开始是在虚拟机中运行的，虚拟机有一个 IP，可以和项目中其他虚拟机通信。这里的模型是基本相同的。

k8s 的 IP 地址存在于 `Pod` 范围内 -- 容器共享它们的网络命名空间 -- 包括它们的 IP 地址和 MAC 地址。这就意味着 `Pod` 内的容器都可以通过 `localhost` 到达对方端口。这也就意味着 `Pod` 内的容器需要相互协调端口的使用，这和虚拟机中的进程相同，因此也被称为”一个 Pod 一个 IP“模型。

如何实现上述需求是使用的特定容器运行时的细节。

也可以在 `Node` 本身请求端口，并用这类端口转发到用户的 `Pod`（称之为主机端口），但这是一个很特殊的操作。转发方式如何实现也是容器运行时的细节。`Pod` 自己并不知道这些主机端口的存在。

k8s 网络解决四方面的问题：

- 一个 Pod 中的容器之间通过本地回路（loopback）通信。
- 集群网络在不同 pod 之间提供通信。
- 服务资源允许用户向外暴露 Pods 中运行的应用，用来支持来自于集群外部的访问。
- 可以使用服务来发布仅供集群内部使用的服务。

## 服务 Service

WIP

## 使用拓扑键实现拓扑感知的流量路由

WIP

## Pod 与服务的 DNS

WIP

## 使用服务连接到应用

WIP

## Ingress

WIP

## Ingress 控制器

WIP

## 端点切片

WIP

## 服务内部流量策略

WIP

## 拓扑感知提示

WIP

## 网络策略

WIP

## IPv4/IPv6 双协议栈

WIP
